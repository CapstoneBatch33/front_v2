# ğŸŒ± Smart Farm Dashboard & AI Chatbot

A comprehensive smart farming solution with real-time sensor monitoring, data visualization, and an AI-powered farming assistant chatbot.

## ğŸš€ Features

- **ğŸ“Š Real-time Dashboard** - Monitor soil moisture, temperature, pH, and other vital metrics
- **ğŸ¤– AI Farming Assistant** - Chat with TinyLlama for farming advice and recommendations
- **ğŸ“ˆ Data Visualization** - Interactive charts and graphs for sensor data analysis
- **ğŸ–¼ï¸ Plant Disease Detection** - Upload plant images for AI-powered disease identification
- **ğŸ“± Responsive Design** - Works seamlessly on desktop and mobile devices
- **ğŸ”„ Live Data Updates** - Real-time sensor data from IoT devices

## ğŸ› ï¸ Tech Stack

- **Frontend**: Next.js 14, React, TypeScript, Tailwind CSS
- **Backend**: Node.js, Express, Python Flask
- **AI**: Ollama (TinyLlama), TensorFlow.js
- **UI Components**: shadcn/ui, Radix UI
- **Charts**: Recharts
- **Styling**: Tailwind CSS, Framer Motion

## ğŸ“‹ Prerequisites

Before running the project, ensure you have the following installed:

- **Node.js** (v16 or higher) - [Download here](https://nodejs.org/)
- **Python** (v3.8 or higher) - [Download here](https://python.org/)
- **Ollama** - [Download here](https://ollama.ai/)
- **Git** - [Download here](https://git-scm.com/)

## ğŸ”§ Installation

### 1. Clone the Repository
```bash
git clone <your-repository-url>
cd smart-farm-dashboard
```

### 2. Install Node.js Dependencies
```bash
npm install
```

### 3. Install Python Dependencies
```bash
pip install -r requirements.txt
```

### 4. Install and Setup Ollama
```bash
# Install Ollama (follow instructions for your OS from https://ollama.ai)

# Start Ollama service
ollama serve

# Pull the TinyLlama model (in a new terminal)
ollama pull tinyllama

# Test Ollama (optional)
ollama run tinyllama "Hello, how are you?"
```

## ğŸš€ Running the Application

You have two options to run the complete system:

### Option A: Automated Startup (Recommended)
```bash
npm run start-chatbot
```
This will start all services automatically.

### Option B: Manual Startup

#### Terminal 1: Start Ollama Service
```bash
ollama serve
```

#### Terminal 2: Start Python Backend (Sensor Data)
```bash
python smart_farm_server.py
```

#### Terminal 3: Start Node.js Backend (AI Chatbot)
```bash
node ollama-server.js
```

#### Terminal 4: Start Next.js Frontend
```bash
npm run dev
```

## ğŸŒ Access the Application

Once all services are running:

- **ğŸ  Main Dashboard**: http://localhost:3000
- **ğŸ¤– AI Chatbot**: http://localhost:3000/chatbot
- **ğŸ“Š Sensor History**: http://localhost:3000/sensor-history
- **ğŸ”§ Backend API**: http://localhost:3001
- **ğŸ Python API**: http://localhost:8080

## ğŸ“± How to Use

### Dashboard Features
1. **Real-time Monitoring**: View live sensor data on the main dashboard
2. **Historical Data**: Check sensor trends and patterns over time
3. **Health Cards**: Generate soil health reports and recommendations

### AI Chatbot Features
1. **Ask Questions**: Type farming-related questions in natural language
2. **Get Recommendations**: Receive personalized advice based on your sensor data
3. **Image Analysis**: Upload plant photos to detect diseases
4. **Smart Suggestions**: Get contextual suggestions based on your queries

### Example Questions for the AI Chatbot
- "What's the best fertilizer for corn?"
- "How often should I water my tomatoes?"
- "What are signs of plant disease?"
- "What crops should I plant this season?"
- "My soil pH is 6.2, is that good?"

## ğŸ”§ Configuration

### Environment Variables
Create a `.env.local` file in the root directory:
```env
# Optional: Add any API keys or configuration
NEXT_PUBLIC_API_URL=http://localhost:3001
PYTHON_API_URL=http://localhost:8080
```

### Sensor Configuration
Edit `smart_farm_server.py` to configure your sensor endpoints and data sources.

### AI Model Configuration
Edit `ollama-server.js` to customize the AI assistant's behavior and responses.

## ğŸ§ª Testing

### Test the Complete Setup
```bash
npm run test-chatbot
```

### Test Individual Components
```bash
# Test frontend only
npm run dev

# Test Python backend
python smart_farm_server.py

# Test Node.js backend
node ollama-server.js
```

## ğŸ“Š API Endpoints

### Frontend API Routes
- `GET /api/sensor-data` - Get current sensor readings
- `GET /api/sensor-history` - Get historical sensor data
- `POST /api/assistant` - Chat with AI assistant

### Python Backend (Port 8080)
- `GET /api/sensor-data` - Real sensor data from IoT devices
- `POST /api/generate-health-card` - Generate soil health reports

### Node.js Backend (Port 3001)
- `POST /api/assistant` - AI chatbot powered by Ollama
- `GET /api/sensor-data` - Proxy to Python backend

## ğŸš¨ Troubleshooting

### Common Issues

#### 1. Ollama Not Working
```bash
# Check if Ollama is installed
ollama --version

# Start Ollama service
ollama serve

# Pull the model again
ollama pull tinyllama
```

#### 2. Port Already in Use
```bash
# Kill processes on specific ports
# Windows
netstat -ano | findstr :3000
taskkill /PID <PID> /F

# macOS/Linux
lsof -ti:3000 | xargs kill -9
```

#### 3. Python Dependencies Issues
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 4. Node.js Dependencies Issues
```bash
# Clear npm cache
npm cache clean --force

# Delete node_modules and reinstall
rm -rf node_modules package-lock.json
npm install
```

### Error Messages

| Error | Solution |
|-------|----------|
| "Connection refused" | Make sure all servers are running |
| "Model not found" | Run `ollama pull tinyllama` |
| "Port 3000 in use" | Kill the process or use a different port |
| "Python module not found" | Install requirements: `pip install -r requirements.txt` |

## ğŸ“ Project Structure

```
smart-farm-dashboard/
â”œâ”€â”€ app/                          # Next.js app directory
â”‚   â”œâ”€â”€ dashboard/               # Dashboard page
â”‚   â”œâ”€â”€ chatbot/                # AI chatbot page
â”‚   â”œâ”€â”€ api/                    # API routes
â”‚   â””â”€â”€ globals.css             # Global styles
â”œâ”€â”€ components/                  # React components
â”‚   â”œâ”€â”€ ui/                     # shadcn/ui components
â”‚   â””â”€â”€ navbar.tsx              # Navigation component
â”œâ”€â”€ lib/                        # Utility libraries
â”‚   â”œâ”€â”€ utils.ts               # Helper functions
â”‚   â””â”€â”€ model-loader.js        # AI model loader
â”œâ”€â”€ public/                     # Static assets
â”œâ”€â”€ data/                       # Data files
â”œâ”€â”€ ollama-server.js           # AI chatbot backend
â”œâ”€â”€ smart_farm_server.py       # Sensor data backend
â”œâ”€â”€ start-chatbot.js           # Startup script
â”œâ”€â”€ package.json               # Node.js dependencies
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -m 'Add feature'`
4. Push to branch: `git push origin feature-name`
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

If you encounter any issues:

1. Check the [Troubleshooting](#-troubleshooting) section
2. Run the test script: `npm run test-chatbot`
3. Check server logs in each terminal
4. Ensure all prerequisites are installed correctly

## ğŸ¯ Quick Start Checklist

- [ ] Node.js installed
- [ ] Python installed  
- [ ] Ollama installed and running
- [ ] Dependencies installed (`npm install` & `pip install -r requirements.txt`)
- [ ] TinyLlama model downloaded (`ollama pull tinyllama`)
- [ ] All servers running (Python, Node.js, Ollama, Next.js)
- [ ] Accessing dashboard at http://localhost:3000

---

**Happy Farming! ğŸŒ¾ğŸšœ**